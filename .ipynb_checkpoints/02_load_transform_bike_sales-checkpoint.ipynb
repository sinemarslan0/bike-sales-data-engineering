{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abf72dd3-da4b-49dd-bd49-2ffc271d79fb",
   "metadata": {},
   "source": [
    "# üö¥‚Äç‚ôÄÔ∏è Bike Sales ‚Äì Data Transformation & Loading (ETL Step 2)\n",
    "\n",
    "This notebook represents the **second stage of the ETL pipeline** for the Bike Sales dataset.  \n",
    "After completing the exploratory analysis in `01_eda_bike_sales.ipynb`, we now focus on transforming the raw data into a clean, structured format suitable for loading into a SQL Server data warehouse.\n",
    "\n",
    "### Goals:\n",
    "- Clean and normalize all 8 tables\n",
    "- Convert data types (e.g., dates, numeric fields)\n",
    "- Drop irrelevant or empty columns\n",
    "- Prepare foreign key relationships\n",
    "- Save cleaned data for loading into SQL Server\n",
    "\n",
    "### Steps:\n",
    "1. **Load Raw CSV Files**  \n",
    "   Import all original tables from the `data/` directory\n",
    "\n",
    "2. **Drop Unnecessary Columns**  \n",
    "   Remove columns that are entirely null or irrelevant for analysis\n",
    "\n",
    "3. **Convert Data Types**  \n",
    "   Ensure correct formats for datetime, numeric, and categorical fields\n",
    "\n",
    "4. **Normalize & Standardize**  \n",
    "   Apply string normalization, fix inconsistent values, and prepare keys\n",
    "\n",
    "5. **Export Cleaned Tables**  \n",
    "   Save transformed tables to `data/cleaned/` for use in the next ETL stage\n",
    "\n",
    "---\n",
    "\n",
    "üìå This transformation step ensures data integrity and consistency before loading into the SQL Server environment via `03_load_to_sqlserver.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d3d44-7c13-4b8a-a641-18caed758388",
   "metadata": {},
   "source": [
    "### **Step 1 :** Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a592dc-e57c-4a7b-b26e-ef32ada195d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b761f-00fb-4add-8d73-d0a49dda6105",
   "metadata": {},
   "source": [
    "### **Step 2:** Load all the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904885ec-1d4c-4a71-aef9-dbea23465aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets with encoding fallback\n",
    "addresses = pd.read_csv(\"data/Addresses.csv\", encoding=\"ISO-8859-1\")\n",
    "business_partners = pd.read_csv(\"data/BusinessPartners.csv\", encoding=\"ISO-8859-1\")\n",
    "employees = pd.read_csv(\"data/Employees.csv\", encoding=\"ISO-8859-1\")\n",
    "product_categories = pd.read_csv(\"data/ProductCategories.csv\", encoding=\"ISO-8859-1\")\n",
    "products = pd.read_csv(\"data/Products.csv\", encoding=\"ISO-8859-1\")\n",
    "product_texts = pd.read_csv(\"data/ProductTexts.csv\", encoding=\"ISO-8859-1\")\n",
    "sales_order_items = pd.read_csv(\"data/SalesOrderItems.csv\", encoding=\"ISO-8859-1\")\n",
    "sales_orders = pd.read_csv(\"data/SalesOrders.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7170bd2-e600-483e-b275-0a39554cb442",
   "metadata": {},
   "source": [
    "### **Step 3:** Clean `addresses` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873d6946-6412-4c91-b738-7a834294bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column with BOM artifact if necessary\n",
    "addresses.rename(columns={\"√Ø¬ª¬øADDRESSID\": \"ADDRESSID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f5b73c-7a59-49f3-ac93-64d3b0492f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop `VALIDITY_STARTDATE` and `VALIDITY_ENDDATE` due to placeholder values (`20000101`, `99991231`) that do not reflect employee validity periods.\n",
    "addresses.drop(columns=[\"VALIDITY_STARTDATE\", \"VALIDITY_ENDDATE\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f3bfa26-aef6-4d55-9a43-5b865b210023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54 entries, 0 to 53\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ADDRESSID    54 non-null     int64  \n",
      " 1   CITY         54 non-null     object \n",
      " 2   POSTALCODE   54 non-null     object \n",
      " 3   STREET       54 non-null     object \n",
      " 4   BUILDING     48 non-null     float64\n",
      " 5   COUNTRY      54 non-null     object \n",
      " 6   REGION       54 non-null     object \n",
      " 7   ADDRESSTYPE  54 non-null     int64  \n",
      " 8   LATITUDE     54 non-null     float64\n",
      " 9   LONGITUDE    54 non-null     float64\n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 4.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "addresses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445d207e-9323-4f09-b577-e407a07d553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned addresses table\n",
    "cleaned_path = \"data/cleaned/\"\n",
    "os.makedirs(cleaned_path, exist_ok=True)\n",
    "\n",
    "addresses.to_csv(\"data/cleaned/addresses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a296152-50ee-4538-a781-6a0b15cae125",
   "metadata": {},
   "source": [
    "### Note: Transforming `addresses` Table\n",
    "\n",
    "- Renamed column `√Ø¬ª¬øADDRESSID` to `ADDRESSID` to remove BOM artifact.\n",
    "- Dropped `VALIDITY_STARTDATE` and `VALIDITY_ENDDATE` columns due to irrelevance and redundancy.\n",
    "- Saved cleaned table to `data/cleaned/addresses.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac19d7-64ae-4f03-91eb-da8fe2f8a83e",
   "metadata": {},
   "source": [
    "### **Step 4:** Clean `business_partners` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d36dbf9-152c-47ee-8387-e58c61bff0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop FAXNUMBER column due to excessive missing values\n",
    "business_partners.drop(columns=[\"FAXNUMBER\"], inplace=True)\n",
    "\n",
    "# Convert CREATEDAT and CHANGEDAT to datetime\n",
    "business_partners[\"CREATEDAT\"] = pd.to_datetime(business_partners[\"CREATEDAT\"], format=\"%Y%m%d\")\n",
    "business_partners[\"CHANGEDAT\"] = pd.to_datetime(business_partners[\"CHANGEDAT\"], format=\"%Y%m%d\")\n",
    "\n",
    "# Convert PHONENUMBER to string\n",
    "business_partners[\"PHONENUMBER\"] = business_partners[\"PHONENUMBER\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "675439bc-eda6-4322-836d-0dd9220ec00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   PARTNERID     40 non-null     int64         \n",
      " 1   PARTNERROLE   40 non-null     int64         \n",
      " 2   EMAILADDRESS  40 non-null     object        \n",
      " 3   PHONENUMBER   40 non-null     object        \n",
      " 4   WEBADDRESS    40 non-null     object        \n",
      " 5   ADDRESSID     40 non-null     int64         \n",
      " 6   COMPANYNAME   40 non-null     object        \n",
      " 7   LEGALFORM     40 non-null     object        \n",
      " 8   CREATEDBY     40 non-null     int64         \n",
      " 9   CREATEDAT     40 non-null     datetime64[ns]\n",
      " 10  CHANGEDBY     40 non-null     int64         \n",
      " 11  CHANGEDAT     40 non-null     datetime64[ns]\n",
      " 12  CURRENCY      40 non-null     object        \n",
      "dtypes: datetime64[ns](2), int64(5), object(6)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "business_partners.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0155d33c-5a80-429c-a295-d27c79848430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned business_partners table\n",
    "business_partners.to_csv(\"data/cleaned/business_partners.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2466da-1778-43db-bdf5-6df9bda2a771",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Note: Transforming `business_partners` Table\n",
    "\n",
    "- Dropped `FAXNUMBER` and `ADDRESS` columns due to irrelevance and redundancy.\n",
    "- Converted `CREATEDAT` and `CHANGEDAT` to proper datetime format.\n",
    "- Cast `PHONENUMBER` from integer to string for consistency.\n",
    "- Saved cleaned table to `data/cleaned/business_partners.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5879b5-876b-47e4-a3ba-cfaba4677bab",
   "metadata": {},
   "source": [
    "### **Step 5:** Clean `employees` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e086adc-9d28-409f-b311-9d2ee355e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "employees.drop(columns=[\n",
    "    \"NAME_INITIALS\",\n",
    "    \"Unnamed: 13\", \"Unnamed: 14\", \"Unnamed: 15\",\n",
    "    \"Unnamed: 16\", \"Unnamed: 17\", \"Unnamed: 18\"\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd1a4317-18cf-4a94-a8a5-32fd4090a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop `VALIDITY_STARTDATE` and `VALIDITY_ENDDATE` due to placeholder values (`20000101`, `99991231`) that do not reflect employee validity periods.\n",
    "employees.drop(columns=[\"VALIDITY_STARTDATE\", \"VALIDITY_ENDDATE\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b00224d9-6d1b-4fed-bb45-2ea68825d463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   EMPLOYEEID    14 non-null     int64 \n",
      " 1   NAME_FIRST    14 non-null     object\n",
      " 2   NAME_MIDDLE   12 non-null     object\n",
      " 3   NAME_LAST     14 non-null     object\n",
      " 4   SEX           14 non-null     object\n",
      " 5   LANGUAGE      14 non-null     object\n",
      " 6   PHONENUMBER   14 non-null     object\n",
      " 7   EMAILADDRESS  14 non-null     object\n",
      " 8   LOGINNAME     14 non-null     object\n",
      " 9   ADDRESSID     14 non-null     int64 \n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "employees.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf098973-2349-40ed-8c31-6daded83f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned employees table\n",
    "employees.to_csv(\"data/cleaned/employees.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8223525-c54a-43f7-9360-7949a10bc43d",
   "metadata": {},
   "source": [
    "### **Step 6:** Clean `product_categories` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b457d456-8120-4c45-91b0-43eaa7151426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CREATEDAT to datetime\n",
    "product_categories[\"CREATEDAT\"] = pd.to_datetime(product_categories[\"CREATEDAT\"], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "668cc4f4-75ee-473e-8eb0-badbb4d72a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   PRODCATEGORYID  9 non-null      object        \n",
      " 1   CREATEDBY       9 non-null      int64         \n",
      " 2   CREATEDAT       9 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 348.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "product_categories.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83d2ddd1-c63f-4b26-a874-5336fd320836",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_categories.to_csv(\"data/cleaned/product_categories.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de93f702-47b2-4639-b616-7afe7009d07c",
   "metadata": {},
   "source": [
    "### Note: Transforming `product_categories` Table\n",
    "\n",
    "- Converted `CREATEDAT` to proper datetime format (`YYYYMMDD`).\n",
    "- Saved cleaned table to `data/cleaned/product_categories.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eb56f-8d52-431e-aa87-1934689905ad",
   "metadata": {},
   "source": [
    "### **Step 7:** Clean `products` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54408e3f-773f-460c-b875-c70ce3a5b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns\n",
    "products.drop(columns=[\n",
    "    \"WIDTH\", \"DEPTH\",\n",
    "    \"HEIGHT\", \"DIMENSIONUNIT\",\n",
    "    \"PRODUCTPICURL\"\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18e5cc0e-34b0-4397-91ab-0600a26a47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns\n",
    "products[\"CREATEDAT\"] = pd.to_datetime(products[\"CREATEDAT\"], format=\"%Y%m%d\")\n",
    "products[\"CHANGEDAT\"] = pd.to_datetime(products[\"CHANGEDAT\"], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b1964e8-81c6-429f-ac22-9ab6e3726da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   PRODUCTID           42 non-null     object        \n",
      " 1   TYPECODE            42 non-null     object        \n",
      " 2   PRODCATEGORYID      42 non-null     object        \n",
      " 3   CREATEDBY           42 non-null     int64         \n",
      " 4   CREATEDAT           42 non-null     datetime64[ns]\n",
      " 5   CHANGEDBY           42 non-null     int64         \n",
      " 6   CHANGEDAT           42 non-null     datetime64[ns]\n",
      " 7   SUPPLIER_PARTNERID  42 non-null     int64         \n",
      " 8   TAXTARIFFCODE       42 non-null     int64         \n",
      " 9   QUANTITYUNIT        42 non-null     object        \n",
      " 10  WEIGHTMEASURE       42 non-null     float64       \n",
      " 11  WEIGHTUNIT          42 non-null     object        \n",
      " 12  CURRENCY            42 non-null     object        \n",
      " 13  PRICE               42 non-null     int64         \n",
      "dtypes: datetime64[ns](2), float64(1), int64(5), object(6)\n",
      "memory usage: 4.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "985647f3-a825-448f-9e20-dc412464cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.to_csv(\"data/cleaned/products.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309efd19-0d3f-4d2e-9044-71b86463f24e",
   "metadata": {},
   "source": [
    "### Note: Transforming `products` Table\n",
    "\n",
    "- Dropped irrelevant columns: `WIDTH`, `DEPTH`, `HEIGHT`, `DIMENSIONUNIT`, `PRODUCTURL`.\n",
    "- Converted `CREATEDAT` and `CHANGEDAT` to datetime format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd4413-9eb3-424c-9eb3-daafd4c7c110",
   "metadata": {},
   "source": [
    "### **Step 8:** Clean `product_texts` Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97fc1a05-9851-41db-afed-8a0e2a58cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty column\n",
    "product_texts.drop(columns=[\"LONG_DESCR\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c339bbd-854e-417b-9c5a-477b8225c79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44 entries, 0 to 43\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   PRODUCTID     44 non-null     object\n",
      " 1   LANGUAGE      44 non-null     object\n",
      " 2   SHORT_DESCR   44 non-null     object\n",
      " 3   MEDIUM_DESCR  36 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "product_texts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3593c72-b638-424f-94c3-a0e9db254c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_texts.to_csv(\"data/cleaned/product_texts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b52214b-4cc4-4109-8fe4-8843384ef796",
   "metadata": {},
   "source": [
    "### Note: Transforming `product_texts` Table\n",
    "\n",
    "- Dropped `LONG_DESCR` column due to 100% missing values.\n",
    "- Saved cleaned table to `data/cleaned/product_texts.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f7f77-3edc-4448-a66b-22da4d313649",
   "metadata": {},
   "source": [
    "### **Step 9:** Clean `sales_order_items` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e53fd9ea-ff25-4eb2-b3d8-dee569cfa6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty column\n",
    "sales_order_items.drop(columns=[\"OPITEMPOS\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c7b7550-21b5-48d9-ae26-d7e86e3cfa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DELIVERYDATE to datetime\n",
    "sales_order_items[\"DELIVERYDATE\"] = pd.to_datetime(\n",
    "    sales_order_items[\"DELIVERYDATE\"], format=\"%Y%m%d\", errors=\"coerce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73592cc-ecdf-43fa-9e07-14e57c5035cd",
   "metadata": {},
   "source": [
    "Note: The column `DELIVERYDATE` contained out-of-bounds values such as `29991212`, which exceed pandas' datetime limit (2262-04-11). These were safely coerced to `NaT` using `errors='coerce'` during conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f546f1e5-f358-465a-9130-65b295ef1929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1930 entries, 0 to 1929\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   SALESORDERID    1930 non-null   int64         \n",
      " 1   SALESORDERITEM  1930 non-null   int64         \n",
      " 2   PRODUCTID       1930 non-null   object        \n",
      " 3   NOTEID          1930 non-null   object        \n",
      " 4   CURRENCY        1930 non-null   object        \n",
      " 5   GROSSAMOUNT     1930 non-null   int64         \n",
      " 6   NETAMOUNT       1930 non-null   float64       \n",
      " 7   TAXAMOUNT       1930 non-null   float64       \n",
      " 8   ITEMATPSTATUS   1930 non-null   object        \n",
      " 9   QUANTITY        1930 non-null   int64         \n",
      " 10  QUANTITYUNIT    1930 non-null   object        \n",
      " 11  DELIVERYDATE    1908 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(5)\n",
      "memory usage: 181.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "sales_order_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bbb314e1-b6d2-4196-afca-5fcd52dbee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_order_items.to_csv(\"data/cleaned/sales_order_items.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c7f6d-b410-495a-843b-9b200f3e6840",
   "metadata": {},
   "source": [
    "### Note: Transforming `sales_order_items` Table\n",
    "\n",
    "- Dropped 'OPITEMPOS' column due to 100% missing values.\n",
    "- Converted `DELIVERYDATE` to datetime format.\n",
    "- Saved cleaned table to `data/cleaned/sales_order_items.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1b0bb-9e96-46ac-8641-34e28be3e5e9",
   "metadata": {},
   "source": [
    "### **Step 10:** Clean `sales_orders` Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1615377b-9cd8-4c55-ba9a-109f595482a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty column\n",
    "sales_orders.drop(columns=[\"NOTEID\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99ac6d35-aab4-4984-9468-9a811224b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns\n",
    "sales_orders[\"CREATEDAT\"] = pd.to_datetime(sales_orders[\"CREATEDAT\"], format=\"%Y%m%d\")\n",
    "sales_orders[\"CHANGEDAT\"] = pd.to_datetime(sales_orders[\"CHANGEDAT\"], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e406be8d-8dd7-453a-81b0-82733b35a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fiscal year period to pandas Period type\n",
    "sales_orders[\"FISCAL_PERIOD\"] = sales_orders[\"FISCALYEARPERIOD\"].astype(str).apply(\n",
    "    lambda x: pd.Period(f\"{x[:4]}-{x[-2:]}\", freq=\"M\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cdc959-5079-4beb-8682-603b836c2856",
   "metadata": {},
   "source": [
    "### Fiscal Period Transformation\n",
    "\n",
    "- Converted `FISCALYEARPERIOD` (e.g., `2018011`) to pandas `Period` type (`freq=\"M\"`).\n",
    "- New column `FISCAL_PERIOD` enables month-based time series analysis and dashboard filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9749f052-b615-4714-ad64-531b615f98f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334 entries, 0 to 333\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   SALESORDERID      334 non-null    int64         \n",
      " 1   CREATEDBY         334 non-null    int64         \n",
      " 2   CREATEDAT         334 non-null    datetime64[ns]\n",
      " 3   CHANGEDBY         334 non-null    int64         \n",
      " 4   CHANGEDAT         334 non-null    datetime64[ns]\n",
      " 5   FISCVARIANT       334 non-null    object        \n",
      " 6   FISCALYEARPERIOD  334 non-null    int64         \n",
      " 7   PARTNERID         334 non-null    int64         \n",
      " 8   SALESORG          334 non-null    object        \n",
      " 9   CURRENCY          334 non-null    object        \n",
      " 10  GROSSAMOUNT       334 non-null    int64         \n",
      " 11  NETAMOUNT         334 non-null    float64       \n",
      " 12  TAXAMOUNT         334 non-null    float64       \n",
      " 13  LIFECYCLESTATUS   334 non-null    object        \n",
      " 14  BILLINGSTATUS     334 non-null    object        \n",
      " 15  DELIVERYSTATUS    334 non-null    object        \n",
      " 16  FISCAL_PERIOD     334 non-null    period[M]     \n",
      "dtypes: datetime64[ns](2), float64(2), int64(6), object(6), period[M](1)\n",
      "memory usage: 44.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "sales_orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec4cd184-e6ee-44c7-9154-54ecfbb6a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_orders.to_csv(\"data/cleaned/sales_orders.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440f8db-884f-4bdc-8ab0-9fc0e1f673e9",
   "metadata": {},
   "source": [
    "### Note: Transforming `sales_orders` Table\n",
    "\n",
    "- Dropped empty column `NOTEDID`.\n",
    "- Converted `CREATEDAT` and `CHANGEAT` to datetime format (`%Y%m%d`).\n",
    "- Transformed `FISCALYEARPERIOD` into pandas `Period` type (`freq=\"M\"`), stored in `FISCAL_PERIOD`.\n",
    "- Saved cleaned table to `data/cleaned/product_texts.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aadc04-fea5-456d-8c2b-c53cae056e6d",
   "metadata": {},
   "source": [
    "### Entity Relationship Diagram (ERD)\n",
    "\n",
    "The following diagram was created in Lucidchart based on the relationships identified during the EDA phase.\n",
    "\n",
    "During the transformation process, we removed empty or irrelevant columns, standardized key fields, and adjusted data types to ensure consistency across all 8 tables. The diagram below reflects the cleaned structure and intended relationships between entities.\n",
    "\n",
    "> Note: Foreign key constraints are not yet enforced in pandas, but the relationships shown here will be implemented in the next step (`03_load_to_sqlserver.ipynb`) when the data is loaded into the SQL Server environment.\n",
    "\n",
    "![ERD Diagram](erd_cleaned.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb528128-0bc1-4089-bc9e-14bf75611683",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Final Note: Data Transformation Completed\n",
    "\n",
    "All 8 tables have been successfully cleaned and transformed.\n",
    "\n",
    "- Irrelevant or empty columns removed  \n",
    "- Date fields converted to `datetime` format  \n",
    "- `FISCALYEARPERIOD` transformed into pandas `Period` type for time series analysis\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Step: `03_load_to_sqlserver.ipynb`\n",
    "\n",
    "In the next notebook, we will:\n",
    "\n",
    "- Connect to the SQL Server instance  \n",
    "- Create target tables with appropriate schemas  \n",
    "- Load cleaned data from `data/cleaned/` into the database  \n",
    "- Validate row counts and foreign key integrity  \n",
    "- Prepare the environment for downstream analytics and dashboarding\n",
    "\n",
    "Let‚Äôs move from clean files to a fully structured data warehouse üí°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe7cf45-bd9c-432b-b5f2-8af3ae4c6b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
